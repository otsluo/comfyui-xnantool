import requests
import json
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
import base64
import time

# æ£€æŸ¥openaiåº“æ˜¯å¦å¯ç”¨
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# å¯¼å…¥å¿…è¦çš„å‡½æ•°
from .modelscope_api_node import load_config, load_api_token, save_api_token, tensor_to_base64_url

# æ”¯æŒçš„å›¾ç‰‡åæ¨æ¨¡å‹åˆ—è¡¨
SUPPORTED_CAPTION_MODELS = [
    ("Qwen/Qwen3-VL-235B-A22B-Instruct", "Qwen3-VL 235B A22B Instruct"),
    ("Qwen/Qwen3-VL-8B-Instruct", "Qwen3-VL 8B Instruct"),
    ("Qwen/Qwen3-VL-2B-Instruct", "Qwen3-VL 2B Instruct"),
]

class ModelscopeApiImageCaptionNode:
    """é­”æ­APIå›¾ç‰‡åæ¨èŠ‚ç‚¹ - ç”¨äºä»å›¾åƒç”Ÿæˆæè¿°æ–‡æœ¬"""
    def __init__(self):
        pass
    
    def parse_api_token(self, token_input):
        """è§£æè¾“å…¥çš„å•ä¸ªAPI Token"""
        if not token_input or token_input.strip() == "":
            # å°è¯•åŠ è½½ä¿å­˜çš„token
            saved_token = load_api_token()
            if saved_token:
                return saved_token
            return ""
        
        # è¿”å›å•ä¸ªToken
        return token_input.strip()
    
    @classmethod
    def INPUT_TYPES(cls):
        if not OPENAI_AVAILABLE:
            return {
                "required": {
                    "error_message": ("STRING", {
                        "default": "è¯·å…ˆå®‰è£…openaiåº“: pip install openai",
                        "multiline": True
                    }),
                }
            }
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "image": ("IMAGE",),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "label": "API Token",
                    "description": "modelscope API ä»¤ç‰Œ",
                    "placeholder": "è¯·è¾“å…¥æ‚¨çš„ modelscope API Token",
                    "multiline": False
                }),
                "model_name": ("STRING", {
                    "default": "Qwen/Qwen3-VL-235B-A22B-Instruct",
                    "options": [model[0] for model in SUPPORTED_CAPTION_MODELS],
                    "labels": {model[0]: model[1] for model in SUPPORTED_CAPTION_MODELS},
                    "label": "æ¨¡å‹åç§°"
                }),
            },
            "optional": {
                "prompt": ("STRING", {
                    "default": "è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€èƒŒæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ä¿¡æ¯",
                    "label": "æç¤ºè¯",
                    "description": "ç”¨äºå›¾ç‰‡æè¿°çš„æç¤ºè¯",
                    "multiline": True
                }),
                "max_tokens": ("INT", {
                    "default": 1000,
                    "min": 100,
                    "max": 4000,
                    "label": "æœ€å¤§ä»¤ç‰Œæ•°",
                    "description": "ç”Ÿæˆæè¿°æ–‡æœ¬çš„æœ€å¤§é•¿åº¦"
                }),
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1,
                    "label": "æ¸©åº¦ç³»æ•°",
                    "description": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("å›¾ç‰‡æè¿°",)
    FUNCTION = "generate_caption"
    CATEGORY = "XnanTool/é­”æ­api"
    
    def generate_caption(self, image, api_token, model_name, prompt="è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€èƒŒæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ä¿¡æ¯", max_tokens=1000, temperature=0.7):
        if not OPENAI_AVAILABLE:
            return ("è¯·å…ˆå®‰è£…openaiåº“: pip install openai",)
        
        # è§£æå•ä¸ªAPI Token
        token = self.parse_api_token(api_token)
        if not token:
            raise Exception("è¯·è¾“å…¥æœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜æ–°Tokenï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
        saved_token = load_api_token()
        if api_token.strip() != saved_token:
            if save_api_token(token):
                print("âœ… API Tokenå·²è‡ªåŠ¨ä¿å­˜")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        try:
            print(f"ğŸ” å¼€å§‹ç”Ÿæˆå›¾åƒæè¿°...")
            print(f"ğŸ“ æç¤ºè¯: {prompt}")
            print(f"ğŸ¤– æ¨¡å‹: {model_name}")
            print(f"ğŸ”‘ ä½¿ç”¨API Token: {token[:10]}...")
            
            # è½¬æ¢å›¾åƒä¸ºbase64æ ¼å¼
            image_url = tensor_to_base64_url(image)
            print(f"ğŸ–¼ï¸ å›¾åƒå·²è½¬æ¢ä¸ºbase64æ ¼å¼")
            
            # æ„å»ºæ¶ˆæ¯ä½“
            messages = [{
                'role': 'user',
                'content': [{
                    'type': 'text',
                    'text': prompt,
                }, {
                    'type': 'image_url',
                    'image_url': {
                        'url': image_url,
                    },
                }],
            }]
            
            try:
                print(f"ğŸ”„ ä½¿ç”¨API Tokenè¿›è¡Œè°ƒç”¨...")
                
                # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                client = OpenAI(
                    base_url='https://api-inference.modelscope.cn/v1',
                    api_key=token
                )
                
                # è°ƒç”¨APIï¼ˆä½¿ç”¨é€‰ä¸­çš„æ¨¡å‹ï¼‰
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    stream=False
                )
                
                # æˆåŠŸè·å–ç»“æœ
                description = response.choices[0].message.content
                print(f"âœ… APIè°ƒç”¨æˆåŠŸ!")
                print(f"ğŸ“„ ç»“æœé¢„è§ˆ: {description[:100]}...")
                return (description,)
                
            except Exception as e:
                error_msg = f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                return (error_msg,)
            
        except Exception as e:
            error_msg = f"å›¾åƒæè¿°ç”Ÿæˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return (error_msg,)

# èŠ‚ç‚¹æ˜ å°„å’Œæ˜¾ç¤ºåç§°æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ModelscopeApiImageCaptionNode": ModelscopeApiImageCaptionNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelscopeApiImageCaptionNode": "é­”æ­API-å›¾ç‰‡åæ¨èŠ‚ç‚¹",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']