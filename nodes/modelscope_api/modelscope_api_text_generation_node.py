import requests
import json
import os
import time

# æ£€æŸ¥openaiåº“æ˜¯å¦å¯ç”¨
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# å¯¼å…¥å¿…è¦çš„å‡½æ•°
from .modelscope_api_node import load_config, load_api_token, save_api_token

# æ”¯æŒçš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åˆ—è¡¨
SUPPORTED_TEXT_GENERATION_MODELS = [
    ("Qwen/Qwen3-VL-235B-A22B-Instruct", "Qwen3-VL 235B A22B Instruct"),
]

class ModelscopeApiTextGenerationNode:
    """é­”æ­APIæ–‡æœ¬ç”ŸæˆèŠ‚ç‚¹ - ç”¨äºç”Ÿæˆæ–‡æœ¬å†…å®¹"""
    def __init__(self):
        pass
    
    def parse_api_token(self, token_input):
        """è§£æè¾“å…¥çš„å•ä¸ªAPI Token"""
        if not token_input or token_input.strip() == "":
            # å°è¯•åŠ è½½ä¿å­˜çš„token
            saved_token = load_api_token()
            if saved_token:
                return saved_token
            return ""
        
        # è¿”å›å•ä¸ªToken
        return token_input.strip()
    
    @classmethod
    def INPUT_TYPES(cls):
        if not OPENAI_AVAILABLE:
            return {
                "required": {
                    "error_message": ("STRING", {
                        "default": "è¯·å…ˆå®‰è£…openaiåº“: pip install openai",
                        "multiline": True
                    }),
                }
            }
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "prompt": ("STRING", {
                    "default": "è¯·ç”Ÿæˆä¸€æ®µå…³äºäººå·¥æ™ºèƒ½çš„æ–‡æœ¬",
                    "label": "æç¤ºè¯",
                    "description": "ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„æç¤ºè¯",
                    "multiline": True
                }),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "label": "API Token",
                    "description": "modelscope API ä»¤ç‰Œ",
                    "placeholder": "è¯·è¾“å…¥æ‚¨çš„ modelscope API Token",
                    "multiline": False
                }),
                "model_name": ("STRING", {
                    "default": "Qwen/Qwen3-VL-235B-A22B-Instruct",
                    "options": [model[0] for model in SUPPORTED_TEXT_GENERATION_MODELS],
                    "labels": {model[0]: model[1] for model in SUPPORTED_TEXT_GENERATION_MODELS},
                    "label": "æ¨¡å‹åç§°"
                }),
            },
            "optional": {
                "system_prompt": ("STRING", {
                    "default": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹",
                    "label": "ç³»ç»Ÿæç¤ºè¯",
                    "description": "ç³»ç»Ÿçº§åˆ«çš„æç¤ºè¯ï¼Œç”¨äºè®¾å®šAIçš„è¡Œä¸º",
                    "multiline": True
                }),
                "max_tokens": ("INT", {
                    "default": 1000,
                    "min": 100,
                    "max": 4000,
                    "label": "æœ€å¤§ä»¤ç‰Œæ•°",
                    "description": "ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦"
                }),
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1,
                    "label": "æ¸©åº¦ç³»æ•°",
                    "description": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.9,
                    "min": 0.1,
                    "max": 1.0,
                    "step": 0.1,
                    "label": "Top P",
                    "description": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("ç”Ÿæˆæ–‡æœ¬",)
    FUNCTION = "generate_text"
    CATEGORY = "XnanTool/é­”æ­api"
    
    def generate_text(self, prompt, api_token, model_name, system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹", max_tokens=1000, temperature=0.7, top_p=0.9):
        if not OPENAI_AVAILABLE:
            return ("è¯·å…ˆå®‰è£…openaiåº“: pip install openai",)
        
        # è§£æå•ä¸ªAPI Token
        token = self.parse_api_token(api_token)
        if not token:
            raise Exception("è¯·è¾“å…¥æœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜æ–°Tokenï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
        saved_token = load_api_token()
        if api_token.strip() != saved_token:
            if save_api_token(token):
                print("âœ… API Tokenå·²è‡ªåŠ¨ä¿å­˜")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        try:
            print(f"ğŸ“ å¼€å§‹ç”Ÿæˆæ–‡æœ¬...")
            print(f"ğŸ”¤ æç¤ºè¯: {prompt}")
            print(f"ğŸ¤– æ¨¡å‹: {model_name}")
            print(f"ğŸ”‘ ä½¿ç”¨API Token: {token[:10]}...")
            
            try:
                print(f"ğŸ”„ ä½¿ç”¨API Tokenè¿›è¡Œè°ƒç”¨...")
                
                # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                client = OpenAI(
                    base_url='https://api-inference.modelscope.cn/v1',
                    api_key=token
                )
                
                # æ„å»ºæ¶ˆæ¯ä½“
                messages = []
                if system_prompt.strip():
                    messages.append({
                        'role': 'system',
                        'content': system_prompt,
                    })
                
                messages.append({
                    'role': 'user',
                    'content': prompt,
                })
                
                # è°ƒç”¨APIï¼ˆä½¿ç”¨é€‰ä¸­çš„æ¨¡å‹ï¼‰
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    stream=False
                )
                
                # æˆåŠŸè·å–ç»“æœ
                generated_text = response.choices[0].message.content
                print(f"âœ… APIè°ƒç”¨æˆåŠŸ!")
                print(f"ğŸ“„ ç»“æœé¢„è§ˆ: {generated_text[:100]}...")
                return (generated_text,)
                
            except Exception as e:
                error_msg = f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                return (error_msg,)
            
        except Exception as e:
            error_msg = f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return (error_msg,)

# èŠ‚ç‚¹æ˜ å°„å’Œæ˜¾ç¤ºåç§°æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ModelscopeApiTextGenerationNode": ModelscopeApiTextGenerationNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelscopeApiTextGenerationNode": "é­”æ­API-æ–‡æœ¬ç”ŸæˆèŠ‚ç‚¹",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']