import requests
import json
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
import base64
import time

# æ£€æŸ¥openaiåº“æ˜¯å¦å¯ç”¨
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# å¯¼å…¥å¿…è¦çš„å‡½æ•°
from .modelscope_api_node import load_config, load_api_token, save_api_token, tensor_to_base64_url

# æ”¯æŒçš„è§†é¢‘åæ¨æ¨¡å‹åˆ—è¡¨
SUPPORTED_VIDEO_CAPTION_MODELS = [
    ("Qwen/Qwen3-VL-235B-A22B-Instruct", "Qwen3-VL 235B A22B Instruct"),
    ("Qwen/Qwen2-VL-72B-Instruct", "Qwen2-VL 72B Instruct"),
    ("Qwen/Qwen2-VL-7B-Instruct", "Qwen2-VL 7B Instruct"),
    ("Qwen/Qwen-VL-Chat", "Qwen-VL Chat"),
]

class ModelscopeApiVideoCaptionNode:
    """é­”æ­APIè§†é¢‘åæ¨èŠ‚ç‚¹ - ç”¨äºä»è§†é¢‘ç”Ÿæˆæè¿°æ–‡æœ¬"""
    def __init__(self):
        pass
    
    def parse_api_token(self, token_input):
        """è§£æè¾“å…¥çš„å•ä¸ªAPI Token"""
        if not token_input or token_input.strip() == "":
            # å°è¯•åŠ è½½ä¿å­˜çš„token
            saved_token = load_api_token()
            if saved_token:
                return saved_token
            return ""
        
        # è¿”å›å•ä¸ªToken
        return token_input.strip()
    
    @classmethod
    def INPUT_TYPES(cls):
        if not OPENAI_AVAILABLE:
            return {
                "required": {
                    "error_message": ("STRING", {
                        "default": "è¯·å…ˆå®‰è£…openaiåº“: pip install openai",
                        "multiline": True
                    }),
                }
            }
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "video_frames": ("IMAGE",),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "label": "API Token",
                    "description": "modelscope API ä»¤ç‰Œ",
                    "placeholder": "è¯·è¾“å…¥æ‚¨çš„ modelscope API Token",
                    "multiline": False
                }),
                "model_name": ("STRING", {
                    "default": "Qwen/Qwen3-VL-235B-A22B-Instruct",
                    "options": [model[0] for model in SUPPORTED_VIDEO_CAPTION_MODELS],
                    "labels": {model[0]: model[1] for model in SUPPORTED_VIDEO_CAPTION_MODELS},
                    "label": "æ¨¡å‹åç§°"
                }),
            },
            "optional": {
                "prompt": ("STRING", {
                    "default": "è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ï¼ŒåŒ…æ‹¬åœºæ™¯ã€åŠ¨ä½œã€ä¸»ä½“ã€èƒŒæ™¯ç­‰ä¿¡æ¯",
                    "label": "æç¤ºè¯",
                    "description": "ç”¨äºè§†é¢‘æè¿°çš„æç¤ºè¯",
                    "multiline": True
                }),
                "max_tokens": ("INT", {
                    "default": 1000,
                    "min": 100,
                    "max": 4000,
                    "label": "æœ€å¤§ä»¤ç‰Œæ•°",
                    "description": "ç”Ÿæˆæè¿°æ–‡æœ¬çš„æœ€å¤§é•¿åº¦"
                }),
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1,
                    "label": "æ¸©åº¦ç³»æ•°",
                    "description": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("è§†é¢‘æè¿°",)
    FUNCTION = "generate_caption"
    CATEGORY = "XnanTool/é­”æ­api"
    
    def generate_caption(self, video_frames, api_token, model_name, prompt="è¯·è¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ï¼ŒåŒ…æ‹¬åœºæ™¯ã€åŠ¨ä½œã€ä¸»ä½“ã€èƒŒæ™¯ç­‰ä¿¡æ¯", max_tokens=1000, temperature=0.7):
        if not OPENAI_AVAILABLE:
            return ("è¯·å…ˆå®‰è£…openaiåº“: pip install openai",)
        
        # è§£æå•ä¸ªAPI Token
        token = self.parse_api_token(api_token)
        if not token:
            raise Exception("è¯·è¾“å…¥æœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜æ–°Tokenï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
        saved_token = load_api_token()
        if api_token.strip() != saved_token:
            if save_api_token(token):
                print("âœ… API Tokenå·²è‡ªåŠ¨ä¿å­˜")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        try:
            print(f"ğŸ” å¼€å§‹ç”Ÿæˆè§†é¢‘æè¿°...")
            print(f"ğŸ“ æç¤ºè¯: {prompt}")
            print(f"ğŸ¤– æ¨¡å‹: {model_name}")
            print(f"ğŸ”‘ ä½¿ç”¨API Token: {token[:10]}...")
            
            # è½¬æ¢è§†é¢‘å¸§ä¸ºbase64æ ¼å¼åˆ—è¡¨
            if isinstance(video_frames, torch.Tensor):
                # å¤„ç†è§†é¢‘å¸§å¼ é‡ (batch of images)
                frame_count = video_frames.shape[0]
                print(f"ğŸï¸ è§†é¢‘å¸§æ•°é‡: {frame_count}")
                
                # æ„å»ºæ¶ˆæ¯ä½“ï¼ŒåŒ…å«æ‰€æœ‰è§†é¢‘å¸§
                content = [{
                    'type': 'text',
                    'text': prompt,
                }]
                
                # æ·»åŠ æ‰€æœ‰è§†é¢‘å¸§
                for i in range(frame_count):
                    frame_tensor = video_frames[i:i+1]  # å–å•å¸§
                    frame_url = tensor_to_base64_url(frame_tensor)
                    content.append({
                        'type': 'image_url',
                        'image_url': {
                            'url': frame_url,
                        },
                    })
                
                messages = [{
                    'role': 'user',
                    'content': content,
                }]
            else:
                # å¦‚æœä¸æ˜¯å¼ é‡ï¼Œå°è¯•ç›´æ¥å¤„ç†
                messages = [{
                    'role': 'user',
                    'content': [{
                        'type': 'text',
                        'text': prompt,
                    }],
                }]
            
            try:
                print(f"ğŸ”„ ä½¿ç”¨API Tokenè¿›è¡Œè°ƒç”¨...")
                
                # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                client = OpenAI(
                    base_url='https://api-inference.modelscope.cn/v1',
                    api_key=token
                )
                
                # è°ƒç”¨APIï¼ˆä½¿ç”¨é€‰ä¸­çš„æ¨¡å‹ï¼‰
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    stream=False
                )
                
                # æˆåŠŸè·å–ç»“æœ
                description = response.choices[0].message.content
                print(f"âœ… APIè°ƒç”¨æˆåŠŸ!")
                print(f"ğŸ“„ ç»“æœé¢„è§ˆ: {description[:100]}...")
                return (description,)
                
            except Exception as e:
                error_msg = f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                return (error_msg,)
            
        except Exception as e:
            error_msg = f"è§†é¢‘æè¿°ç”Ÿæˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return (error_msg,)

# èŠ‚ç‚¹æ˜ å°„å’Œæ˜¾ç¤ºåç§°æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ModelscopeApiVideoCaptionNode": ModelscopeApiVideoCaptionNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelscopeApiVideoCaptionNode": "é­”æ­API-è§†é¢‘åæ¨èŠ‚ç‚¹",
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']