import requests
import json
import time
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
import base64
import tempfile
import requests

# ÈÖçÁΩÆÁõ∏ÂÖ≥ÂáΩÊï∞
def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {
            "default_lora_model": "qiyuanai/TikTok_Xiaohongshu_career_line_beauty_v1",
            "timeout": 720,
            "image_download_timeout": 30,
            "default_prompt": "A golden cat",
            "default_edit_prompt": "‰øÆÊîπÂõæÁâá‰∏≠ÁöÑÂÜÖÂÆπ"
        }

def save_config(config: dict) -> bool:
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"‰øùÂ≠òÈÖçÁΩÆÂ§±Ë¥•: {e}")
        return False

def load_api_token():
    token_path = os.path.join(os.path.dirname(__file__), '.modelscope_api_token')
    try:
        cfg = load_config()
        token_from_cfg = cfg.get("api_token", "").strip()
        if token_from_cfg:
            return token_from_cfg
    except Exception as e:
        print(f"ËØªÂèñconfig.json‰∏≠ÁöÑtokenÂ§±Ë¥•: {e}")
    try:
        if os.path.exists(token_path):
            with open(token_path, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                return token if token else ""
        return ""
    except Exception as e:
        print(f"Âä†ËΩΩtokenÂ§±Ë¥•: {e}")
        return ""

def save_api_token(token):
    token_path = os.path.join(os.path.dirname(__file__), '.modelscope_api_token')
    try:
        with open(token_path, 'w', encoding='utf-8') as f:
            f.write(token)
    except Exception as e:
        print(f"‰øùÂ≠òtokenÂ§±Ë¥•(.modelscope_api_token): {e}")
    try:
        cfg = load_config()
        cfg["api_token"] = token
        if save_config(cfg):
            return True
        return False
    except Exception as e:
        print(f"‰øùÂ≠òtokenÂ§±Ë¥•(config.json): {e}")
        return False

def tensor_to_base64_url(image_tensor):
    try:
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor.squeeze(0)
        
        if image_tensor.max() <= 1.0:
            image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            image_np = image_tensor.cpu().numpy().astype(np.uint8)
        
        pil_image = Image.fromarray(image_np)
        
        buffer = BytesIO()
        pil_image.save(buffer, format='JPEG', quality=85)
        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return f"data:image/jpeg;base64,{img_base64}"
        
    except Exception as e:
        print(f"ÂõæÂÉèËΩ¨Êç¢Â§±Ë¥•: {e}")
        raise Exception(f"ÂõæÂÉèÊ†ºÂºèËΩ¨Êç¢Â§±Ë¥•: {str(e)}")

# ÊîØÊåÅÁöÑÂü∫Á°ÄÊ®°ÂûãÂàóË°®
SUPPORTED_TEXT_TO_IMAGE_MODELS = [
    ("Qwen/Qwen-Image", "Qwen-Image"),
    ("black-forest-labs/FLUX.1-schnell", "FLUX.1-schnell"),
    ("stabilityai/stable-diffusion-3-medium-diffusers", "SD3 Medium"),
    ("segmind/Segmind-Vega", "Segmind-Vega"),
    ("stabilityai/stable-diffusion-xl-base-1.0", "SDXL 1.0"),
]

SUPPORTED_IMAGE_EDIT_MODELS = [
    ("Qwen/Qwen-Image-Edit", "Qwen-Image-Edit"),
    ("stabilityai/stable-diffusion-xl-refiner-1.0", "SDXL Refiner"),
    ("runwayml/stable-diffusion-inpainting", "SD Inpainting"),
]

# ‰øÆÊîπÁ±ªÂêç
class modelscopeLoraTextToImageNode:
    """ÊîØÊåÅÂ§öÁßçÂü∫Á°ÄÊ®°ÂûãÁöÑÊñáÁîüÂõæËäÇÁÇπÔºåÂåÖÂê´LoRAÊîØÊåÅ"""
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_prompt", "A beautiful portrait"),
                    "label": "ÊèêÁ§∫ËØç",
                    "description": "ÊèèËø∞ÊÇ®ÊÉ≥Ë¶ÅÁîüÊàêÁöÑÂõæÂÉèÂÜÖÂÆπ",
                    "placeholder": "ÊèèËø∞ÊÇ®ÊÉ≥Ë¶ÅÁîüÊàêÁöÑÂõæÂÉèÂÜÖÂÆπ"
                }),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "label": "API Token",
                    "description": "modelscope API ‰ª§ÁâåÔºåÁî®‰∫éË∞ÉÁî®ÊúçÂä°",
                    "placeholder": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑ modelscope API Token"
                }),
                "base_model": ("STRING", {
                    "default": SUPPORTED_TEXT_TO_IMAGE_MODELS[0][0],
                    "options": [model[0] for model in SUPPORTED_TEXT_TO_IMAGE_MODELS],
                    "labels": {model[0]: model[1] for model in SUPPORTED_TEXT_TO_IMAGE_MODELS},
                    "label": "Âü∫Á°ÄÊ®°Âûã"
                }),
                "lora_model": ("STRING", {
                    "default": config.get("default_lora_model", "qiyuanai/TikTok_Xiaohongshu_career_line_beauty_v1"),
                    "label": "LoRAÊ®°Âûã"
                }),
            },
            "optional": {
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_negative_prompt", ""),
                    "label": "Ë¥üÈù¢ÊèêÁ§∫ËØç",
                    "placeholder": "ÊèèËø∞ÊÇ®‰∏çÊÉ≥Âú®ÂõæÂÉè‰∏≠Âá∫Áé∞ÁöÑÂÜÖÂÆπ"
                }),
                "width": ("INT", {
                    "default": config.get("default_width", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64,
                    "label": "ÂÆΩÂ∫¶"
                }),
                "height": ("INT", {
                    "default": config.get("default_height", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64,
                    "label": "È´òÂ∫¶"
                }),
                "seed": ("INT", {
                    "default": config.get("default_seed", -1),
                    "min": -1,
                    "max": 2147483647,
                    "label": "ÈöèÊú∫ÁßçÂ≠ê"
                }),
                "steps": ("INT", {
                    "default": config.get("default_steps", 30),
                    "min": 1,
                    "max": 100,
                    "label": "ÈááÊ†∑Ê≠•Êï∞"
                }),
                "guidance": ("FLOAT", {
                    "default": config.get("default_guidance", 7.5),
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1,
                    "label": "ÂºïÂØºÁ≥ªÊï∞"
                }),
                "lora_weight": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1,
                    "label": "LoRAÊùÉÈáç"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "generate_with_lora"
    CATEGORY = "XnanTool/È≠îÊê≠api"
    
    def generate_with_lora(self, prompt, api_token, base_model, lora_model, negative_prompt="", 
                          width=512, height=512, seed=-1, steps=30, guidance=7.5, lora_weight=0.8, generate_control="fixed"):
        config = load_config()
        
        # È™åËØÅAPI Token
        if not api_token or api_token.strip() == "":
            raise Exception("ËØ∑ËæìÂÖ•ÊúâÊïàÁöÑAPI Token")
        
        # ‰øùÂ≠òAPI TokenÔºàÂ¶ÇÊûúÊúâÂèòÂåñÔºâ
        saved_token = load_api_token()
        if api_token != saved_token:
            if save_api_token(api_token):
                print("‚úÖ API TokenÂ∑≤Ëá™Âä®‰øùÂ≠ò")
            else:
                print("‚ö†Ô∏è API Token‰øùÂ≠òÂ§±Ë¥•Ôºå‰ΩÜ‰∏çÂΩ±ÂìçÂΩìÂâç‰ΩøÁî®")
        
        try:
            # ÂáÜÂ§áAPIËØ∑Ê±ÇÂèÇÊï∞
            url = 'https://api-inference.modelscope.cn/v1/images/generations'
            
            # Âü∫Á°Äpayload
            payload = {
                'model': base_model,  # ‰ΩøÁî®Áî®Êà∑ÈÄâÊã©ÁöÑÂü∫Á°ÄÊ®°Âûã
                'prompt': prompt,
                'size': f"{width}x{height}",
                'steps': steps,
                'guidance': guidance,
                'loras': [{
                    'name': lora_model,
                    'weight': lora_weight
                }],
                'generate_control': generate_control  # Ê∑ªÂä†ÁîüÊàêÊéßÂà∂ÂèÇÊï∞
            }
            
            # Ê∑ªÂä†ÂèØÈÄâÂèÇÊï∞
            if negative_prompt.strip():
                payload['negative_prompt'] = negative_prompt
                print(f"üö´ Ë¥üÂêëÊèêÁ§∫ËØç: {negative_prompt}")
            
            # Â§ÑÁêÜÁßçÂ≠ê
            if seed != -1:
                payload['seed'] = seed
                print(f"üéØ ‰ΩøÁî®ÊåáÂÆöÁßçÂ≠ê: {seed}")
            else:
                import random
                random_seed = random.randint(0, 2147483647)
                payload['seed'] = random_seed
                print(f"üé≤ ‰ΩøÁî®ÈöèÊú∫ÁßçÂ≠ê: {random_seed}")
            
            # Ê†πÊçÆ‰∏çÂêåÊ®°ÂûãË∞ÉÊï¥ÂèÇÊï∞
            model_display_name = next((model[1] for model in SUPPORTED_TEXT_TO_IMAGE_MODELS if model[0] == base_model), base_model)
            print(f"üîß ‰ΩøÁî®Âü∫Á°ÄÊ®°Âûã: {model_display_name} ({base_model})")
            print(f"üìê ÂõæÂÉèÂ∞∫ÂØ∏: {width}x{height}")
            print(f"üîÑ ÈááÊ†∑Ê≠•Êï∞: {steps}")
            print(f"üé® ÂºïÂØºÁ≥ªÊï∞: {guidance}")
            print(f"üß© ‰ΩøÁî®LoRAÊ®°Âûã: {lora_model}")
            print(f"‚öñÔ∏è LoRAÊùÉÈáç: {lora_weight}")
            
            # ÂáÜÂ§áËØ∑Ê±ÇÂ§¥
            headers = {
                'Authorization': f'Bearer {api_token}',
                'Content-Type': 'application/json',
                'X-ModelScope-Async-Mode': 'true'
            }
            
            # ÂèëÈÄÅËØ∑Ê±Ç
            print("üì§ Ê≠£Âú®Êèê‰∫§LoRAÂõæÂÉèÁîüÊàê‰ªªÂä°...")
            submission_response = requests.post(
                url,
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                headers=headers,
                timeout=config.get("timeout", 60)
            )
            
            # Â§ÑÁêÜËØ∑Ê±ÇÂìçÂ∫î
            if submission_response.status_code != 200:
                raise Exception(f"APIËØ∑Ê±ÇÂ§±Ë¥•: {submission_response.status_code}, {submission_response.text}")
            
            submission_json = submission_response.json()
            
            # Â§ÑÁêÜÂºÇÊ≠•‰ªªÂä°
            image_url = None
            if 'task_id' in submission_json:
                task_id = submission_json['task_id']
                print(f"üïí Â∑≤Êèê‰∫§‰ªªÂä°Ôºå‰ªªÂä°ID: {task_id}ÔºåÂºÄÂßãËΩÆËØ¢...")
                poll_start = time.time()
                max_wait_seconds = max(60, config.get('timeout', 720))
                
                while True:
                    # Êü•ËØ¢‰ªªÂä°Áä∂ÊÄÅ
                    task_resp = requests.get(
                        f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                        headers={
                            'Authorization': f'Bearer {api_token}',
                            'X-ModelScope-Task-Type': 'image_generation'
                        },
                        timeout=config.get("image_download_timeout", 120)
                    )
                    
                    if task_resp.status_code != 200:
                        raise Exception(f"‰ªªÂä°Êü•ËØ¢Â§±Ë¥•: {task_resp.status_code}, {task_resp.text}")
                    
                    data = task_resp.json()
                    task_status = data.get("task_status")
                    
                    if task_status == "SUCCEED":
                        if not data.get("output_images") or len(data["output_images"]) == 0:
                            raise Exception("‰ªªÂä°ÊàêÂäü‰ΩÜÊú™ËøîÂõûÂõæÁâáURL")
                        
                        image_url = data["output_images"][0]
                        print("‚úÖ ‰ªªÂä°ÂÆåÊàêÔºåÂºÄÂßã‰∏ãËΩΩÂõæÁâá...")
                        
                        # ‰∏ãËΩΩÂõæÁâá
                        img_response = requests.get(image_url, timeout=config.get("image_download_timeout", 30))
                        if img_response.status_code != 200:
                            raise Exception(f"ÂõæÁâá‰∏ãËΩΩÂ§±Ë¥•: {img_response.status_code}")
                        
                        # Â§ÑÁêÜÂõæÁâá
                        pil_image = Image.open(BytesIO(img_response.content))
                        if pil_image.mode != 'RGB':
                            pil_image = pil_image.convert('RGB')
                        
                        # ËΩ¨Êç¢‰∏∫ComfyUIÈúÄË¶ÅÁöÑÊ†ºÂºè
                        image_np = np.array(pil_image).astype(np.float32) / 255.0
                        image_tensor = torch.from_numpy(image_np)[None,]
                        
                        print("üéâ ÂõæÁâáÁîüÊàêÂÆåÊàêÔºÅ")
                        return (image_tensor,)
                        
                    elif task_status == "FAILED":
                        error_message = data.get("errors", {}).get("message", "Êú™Áü•ÈîôËØØ")
                        error_code = data.get("errors", {}).get("code", "Êú™Áü•ÈîôËØØÁ†Å")
                        raise Exception(f"‰ªªÂä°Â§±Ë¥•: ÈîôËØØÁ†Å {error_code}, ÈîôËØØ‰ø°ÊÅØ: {error_message}")
                        
                    # Êú™ÂÆåÊàêÔºåÁªßÁª≠ËΩÆËØ¢
                    time.sleep(5)
            else:
                raise Exception(f"Êú™ËØÜÂà´ÁöÑAPIËøîÂõûÊ†ºÂºè: {submission_json}")
        
        except Exception as e:
            print(f"È≠îÊê≠API-LoRAË∞ÉÁî®Â§±Ë¥•: {str(e)}")
            # ÂàõÂª∫‰∏Ä‰∏™Á∫¢Ëâ≤ÈîôËØØÂõæÂÉè‰Ωú‰∏∫ÂõûÈÄÄ
            error_image = Image.new('RGB', (width, height), color='red')
            error_np = np.array(error_image).astype(np.float32) / 255.0
            error_tensor = torch.from_numpy(error_np)[None,]
            return (error_tensor,)

class modelscopeLoraImageEditNode:
    """ÊîØÊåÅÂ§öÁßçÂü∫Á°ÄÊ®°ÂûãÁöÑÂõæÂÉèÁºñËæëËäÇÁÇπÔºåÂåÖÂê´LoRAÊîØÊåÅ"""
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_edit_prompt", "‰øÆÊîπÂõæÁâá‰∏≠ÁöÑÂÜÖÂÆπ"),
                    "label": "ÁºñËæëÊèêÁ§∫ËØç",
                    "description": "ÊèèËø∞ÊÇ®ÊÉ≥Ë¶ÅÂ¶Ç‰ΩïÁºñËæëÂõæÂÉè",
                    "placeholder": "ÊèèËø∞ÊÇ®ÊÉ≥Ë¶ÅÂ¶Ç‰ΩïÁºñËæëÂõæÂÉè"
                }),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "placeholder": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÈ≠îÊê≠API Token",
                    "label": "API‰ª§Áâå"
                }),
                "base_model": ("STRING", {
                    "default": SUPPORTED_IMAGE_EDIT_MODELS[0][0],
                    "options": [model[0] for model in SUPPORTED_IMAGE_EDIT_MODELS],
                    "labels": {model[0]: model[1] for model in SUPPORTED_IMAGE_EDIT_MODELS},
                    "label": "Âü∫Á°ÄÊ®°Âûã"
                }),
                "lora_model": ("STRING", {
                    "default": config.get("default_lora_model", "qiyuanai/TikTok_Xiaohongshu_career_line_beauty_v1"),
                    "label": "LoRAÊ®°Âûã"
                }),
            },
            "optional": {
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "label": "Ë¥üÈù¢ÊèêÁ§∫ËØç",
                    "placeholder": "ÊèèËø∞ÊÇ®‰∏çÊÉ≥Âú®ÁºñËæëÂêéÂõæÂÉè‰∏≠Âá∫Áé∞ÁöÑÂÜÖÂÆπ"
                }),
                "width": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8,
                    "label": "ÂÆΩÂ∫¶"
                }),
                "height": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8,
                    "label": "È´òÂ∫¶"
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647,
                    "label": "ÈöèÊú∫ÁßçÂ≠ê"
                }),
                "steps": ("INT", {
                    "default": 30,
                    "min": 1,
                    "max": 100,
                    "label": "ÈááÊ†∑Ê≠•Êï∞"
                }),
                "guidance": ("FLOAT", {
                    "default": 3.5,
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1,
                    "label": "ÂºïÂØºÁ≥ªÊï∞"
                }),
                "lora_weight": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1,
                    "label": "LoRAÊùÉÈáç"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("edited_image",)
    FUNCTION = "edit_with_lora"
    CATEGORY = "XnanTool/È≠îÊê≠api"
    
    def edit_with_lora(self, image, prompt, api_token, base_model, lora_model, negative_prompt="", 
                       width=512, height=512, seed=-1, steps=30, guidance=3.5, lora_weight=0.8, generate_control="fixed"):
        config = load_config()
        
        # È™åËØÅAPI Token
        if not api_token or api_token.strip() == "":
            raise Exception("ËØ∑ËæìÂÖ•ÊúâÊïàÁöÑAPI Token")
        
        # ‰øùÂ≠òAPI TokenÔºàÂ¶ÇÊûúÊúâÂèòÂåñÔºâ
        saved_token = load_api_token()
        if api_token != saved_token:
            if save_api_token(api_token):
                print("‚úÖ API TokenÂ∑≤Ëá™Âä®‰øùÂ≠ò")
            else:
                print("‚ö†Ô∏è API Token‰øùÂ≠òÂ§±Ë¥•Ôºå‰ΩÜ‰∏çÂΩ±ÂìçÂΩìÂâç‰ΩøÁî®")
        
        try:
            # Â∞ÜÂõæÂÉèËΩ¨Êç¢‰∏∫‰∏¥Êó∂Êñá‰ª∂Âπ∂‰∏ä‰º†Ëé∑ÂèñURL
            temp_img_path = None
            image_url = None
            try:
                # ‰øùÂ≠òÂõæÂÉèÂà∞‰∏¥Êó∂Êñá‰ª∂
                temp_img_path = os.path.join(tempfile.gettempdir(), f"qwen_edit_temp_{int(time.time())}.jpg")
                if len(image.shape) == 4:
                    img = image[0]
                else:
                    img = image
                
                i = 255. * img.cpu().numpy()
                img_pil = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
                img_pil.save(temp_img_path)
                print(f"‚úÖ ÂõæÂÉèÂ∑≤‰øùÂ≠òÂà∞‰∏¥Êó∂Êñá‰ª∂: {temp_img_path}")
                
                # ‰∏ä‰º†ÂõæÂÉèÂà∞kefan.cnËé∑ÂèñURL
                upload_url = 'https://ai.kefan.cn/api/upload/local'
                with open(temp_img_path, 'rb') as img_file:
                    files = {'file': img_file}
                    upload_response = requests.post(
                        upload_url,
                        files=files,
                        timeout=30
                    )
                    if upload_response.status_code == 200:
                        upload_data = upload_response.json()
                        # Ê£ÄÊü•‰∏ä‰º†ÊòØÂê¶ÊàêÂäü
                        if upload_data.get('success') == True and 'data' in upload_data:
                            image_url = upload_data['data']
                            print(f"‚úÖ ÂõæÂÉèÂ∑≤‰∏ä‰º†ÊàêÂäüÔºåËé∑ÂèñURL: {image_url}")
                        else:
                            print(f"‚ö†Ô∏è ÂõæÂÉè‰∏ä‰º†ËøîÂõûÈîôËØØ: {upload_response.text}")
                    else:
                        print(f"‚ö†Ô∏è ÂõæÂÉè‰∏ä‰º†Â§±Ë¥•: {upload_response.status_code}, {upload_response.text}")
            except Exception as e:
                print(f"‚ö†Ô∏è ÂõæÂÉè‰∏ä‰º†ÂºÇÂ∏∏: {str(e)}")
            
            # Â¶ÇÊûú‰∏ä‰º†Â§±Ë¥•ÔºåÂõûÈÄÄÂà∞base64
            if not image_url:
                print("‚ö†Ô∏è ÂõæÂÉèURLËé∑ÂèñÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞‰ΩøÁî®base64")
                image_data = tensor_to_base64_url(image)
                payload = {
                    'model': base_model,  # ‰ΩøÁî®Áî®Êà∑ÈÄâÊã©ÁöÑÂü∫Á°ÄÊ®°Âûã
                    'prompt': prompt,
                    'image': image_data,
                    'loras': [{
                        'name': lora_model,
                        'weight': lora_weight
                    }],
                    'generate_control': generate_control  # Ê∑ªÂä†ÁîüÊàêÊéßÂà∂ÂèÇÊï∞
                }
            else:
                payload = {
                    'model': base_model,  # ‰ΩøÁî®Áî®Êà∑ÈÄâÊã©ÁöÑÂü∫Á°ÄÊ®°Âûã
                    'prompt': prompt,
                    'image_url': image_url,
                    'loras': [{
                        'name': lora_model,
                        'weight': lora_weight
                    }],
                    'generate_control': generate_control  # Ê∑ªÂä†ÁîüÊàêÊéßÂà∂ÂèÇÊï∞
                }
            
            # Ê∑ªÂä†ÂèØÈÄâÂèÇÊï∞
            if negative_prompt.strip():
                payload['negative_prompt'] = negative_prompt
                print(f"üö´ Ë¥üÂêëÊèêÁ§∫ËØç: {negative_prompt}")
            
            # Ê∑ªÂä†Â∞∫ÂØ∏ÂèÇÊï∞
            if width != 512 or height != 512:
                size = f"{width}x{height}"
                payload['size'] = size
                print(f"üìè ÂõæÂÉèÂ∞∫ÂØ∏: {size}")
            
            # Ê∑ªÂä†ÂÖ∂‰ªñÂèÇÊï∞
            if steps != 30:
                payload['steps'] = steps
                print(f"üîÑ ÈááÊ†∑Ê≠•Êï∞: {steps}")
            
            if guidance != 3.5:
                payload['guidance'] = guidance
                print(f"üß≠ ÂºïÂØºÁ≥ªÊï∞: {guidance}")
            
            # Â§ÑÁêÜÁßçÂ≠ê
            if seed != -1:
                payload['seed'] = seed
                print(f"üé≤ ÈöèÊú∫ÁßçÂ≠ê: {seed}")
            
            # Ê†πÊçÆ‰∏çÂêåÊ®°ÂûãË∞ÉÊï¥ÂèÇÊï∞
            model_display_name = next((model[1] for model in SUPPORTED_IMAGE_EDIT_MODELS if model[0] == base_model), base_model)
            print(f"üîß ‰ΩøÁî®Âü∫Á°ÄÊ®°Âûã: {model_display_name} ({base_model})")
            print(f"üß© ‰ΩøÁî®LoRAÊ®°Âûã: {lora_model}")
            print(f"‚öñÔ∏è LoRAÊùÉÈáç: {lora_weight}")
            
            # ÂáÜÂ§áËØ∑Ê±ÇÂ§¥
            headers = {
                'Authorization': f'Bearer {api_token}',
                'Content-Type': 'application/json',
                'X-ModelScope-Async-Mode': 'true'
            }
            
            # ÂèëÈÄÅËØ∑Ê±Ç
            print("üì§ Ê≠£Âú®Êèê‰∫§LoRAÂõæÂÉèÁºñËæë‰ªªÂä°...")
            url = 'https://api-inference.modelscope.cn/v1/images/generations'
            submission_response = requests.post(
                url,
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                headers=headers,
                timeout=config.get("timeout", 60)
            )
            
            # Â§ÑÁêÜËØ∑Ê±ÇÂìçÂ∫î
            if submission_response.status_code != 200:
                raise Exception(f"APIËØ∑Ê±ÇÂ§±Ë¥•: {submission_response.status_code}, {submission_response.text}")
            
            submission_json = submission_response.json()
            
            # Â§ÑÁêÜÂºÇÊ≠•‰ªªÂä°
            result_image_url = None
            if 'task_id' in submission_json:
                task_id = submission_json['task_id']
                print(f"üïí Â∑≤Êèê‰∫§‰ªªÂä°Ôºå‰ªªÂä°ID: {task_id}ÔºåÂºÄÂßãËΩÆËØ¢...")
                poll_start = time.time()
                max_wait_seconds = max(60, config.get('timeout', 720))
                
                while True:
                    # Êü•ËØ¢‰ªªÂä°Áä∂ÊÄÅ
                    task_resp = requests.get(
                        f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                        headers={
                            'Authorization': f'Bearer {api_token}',
                            'X-ModelScope-Task-Type': 'image_generation'
                        },
                        timeout=config.get("image_download_timeout", 120)
                    )
                    
                    if task_resp.status_code != 200:
                        raise Exception(f"‰ªªÂä°Êü•ËØ¢Â§±Ë¥•: {task_resp.status_code}, {task_resp.text}")
                    
                    data = task_resp.json()
                    task_status = data.get("task_status")
                    
                    if task_status == "SUCCEED":
                        if not data.get("output_images") or len(data["output_images"]) == 0:
                            raise Exception("‰ªªÂä°ÊàêÂäü‰ΩÜÊú™ËøîÂõûÂõæÁâáURL")
                        
                        result_image_url = data["output_images"][0]
                        print("‚úÖ ‰ªªÂä°ÂÆåÊàêÔºåÂºÄÂßã‰∏ãËΩΩÁºñËæëÂêéÁöÑÂõæÁâá...")
                        break
                        
                    elif task_status == "FAILED":
                        error_message = data.get("errors", {}).get("message", "Êú™Áü•ÈîôËØØ")
                        error_code = data.get("errors", {}).get("code", "Êú™Áü•ÈîôËØØÁ†Å")
                        raise Exception(f"‰ªªÂä°Â§±Ë¥•: ÈîôËØØÁ†Å {error_code}, ÈîôËØØ‰ø°ÊÅØ: {error_message}")
                        
                    # Ê£ÄÊü•Ë∂ÖÊó∂
                    if time.time() - poll_start > max_wait_seconds:
                        raise Exception("‰ªªÂä°ËΩÆËØ¢Ë∂ÖÊó∂ÔºåËØ∑Á®çÂêéÈáçËØïÊàñÈôç‰ΩéÂπ∂Âèë")
                        
                    # Êú™ÂÆåÊàêÔºåÁªßÁª≠ËΩÆËØ¢
                    time.sleep(5)
            else:
                raise Exception(f"Êú™ËØÜÂà´ÁöÑAPIËøîÂõûÊ†ºÂºè: {submission_json}")
            
            # ‰∏ãËΩΩÁºñËæëÂêéÁöÑÂõæÁâá
            img_response = requests.get(result_image_url, timeout=config.get("image_download_timeout", 30))
            if img_response.status_code != 200:
                raise Exception(f"ÂõæÁâá‰∏ãËΩΩÂ§±Ë¥•: {img_response.status_code}")
            
            # Â§ÑÁêÜÂõæÁâá
            pil_image = Image.open(BytesIO(img_response.content))
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # ËΩ¨Êç¢‰∏∫ComfyUIÈúÄË¶ÅÁöÑÊ†ºÂºè
            image_np = np.array(pil_image).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_np)[None,]
            
            # Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
            if temp_img_path and os.path.exists(temp_img_path):
                try:
                    os.remove(temp_img_path)
                except:
                    pass
            
            print("üéâ ÂõæÁâáÁºñËæëÂÆåÊàêÔºÅ")
            return (image_tensor,)
            
        except Exception as e:
            print(f"È≠îÊê≠API-LoRAÂõæÂÉèÁºñËæëË∞ÉÁî®Â§±Ë¥•: {str(e)}")
            # ËøîÂõûÂéüÂõæÂÉè‰Ωú‰∏∫ÈîôËØØÂõûÈÄÄ
            return (image.unsqueeze(0),)

# ËäÇÁÇπÊò†Â∞ÑÂíåÊòæÁ§∫ÂêçÁß∞Êò†Â∞Ñ
NODE_CLASS_MAPPINGS = {
    "modelscopeLoraTextToImageNode": modelscopeLoraTextToImageNode,
    "modelscopeLoraImageEditNode": modelscopeLoraImageEditNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "modelscopeLoraTextToImageNode": "ÊñáÁîüÂõæËäÇÁÇπ",
    "modelscopeLoraImageEditNode": "ÂõæÂÉèÁºñËæëËäÇÁÇπ"
}

__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS']